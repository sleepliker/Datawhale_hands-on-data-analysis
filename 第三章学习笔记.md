## DataWhale数据分析——学习记录

#### 2020/8/27-2020.8/28 第三章

```python
import pandas as pd 
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from IPython.display import Image
%matplotlib inline # %matplotlib具体作用是当你调用matplotlib.pyplot的绘图函数plot()进行绘图的时候，或者生成一个figure画布的时候，可以直接在你的python console里面生成图像


# 设置图片的细节
plt.rcParams['font.sans-serif'] = ['SimHei'] # 用来正常显示中文标签，字体为SimHei
plt.rcParams['axes.unicode_minus'] = False # 用来正常显示字符
plt.rcParams['figure.figsize'] = (10, 6) # 设置输出图片大小

#读取训练集
train = pd.read_csv('train.csv')
train.shape
```

**特征工程**

数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。而特征工程本质上是一项

工程活动，目的是最大限度地从原始数据中提取特征以供算法和模型使用。https://www.jiqizhixin.com/articles/2018-08-24-4

而构造特征的一般步骤中会涉及预处理数据

https://www.jianshu.com/p/dbcf8aa0ed1e

https://blog.csdn.net/u011094454/article/details/77618604?utm_source=blogxgwz1

```python
# #缺失值的填充
# 对分类变量进行填充：填充某个缺失值字符(NA)、用最多类别的进行填充
train['Cabin'] = train['Cabin'].fillna('NA') # Cabin缺失率较大，根据对数据的理解，填充NA表示无船舱
train['Embarked'] = train['Embarked'].fillna('S') # Embarked（登船口岸）为分类变量，缺失量较小，填最多类别S

#对连续变量进行填充：填充均值、中位数、众数
train['Age'] = train['Age'].fillna(train['Age'].mean()) # Age（年龄）连续性变量，缺失率20%，原始数据呈偏态分布，采用平均数进行填充

# 检查缺失值比例
train.isnull().mean().sort_values(ascending=False) # 输出每个列缺失值（推测：这个mean是指每列的缺失数量/总的缺失数量？因此表示缺失值比例？暂时未找到相关）

# #编码分类变量
data = train[['Pclass','Sex','Age','SibSp','Parch','Fare', 'Embarked']] # 取出所有的输入特征
data = pd.get_dummies(data) # 进行虚拟变量转换，转换为one-hot编码，https://www.jianshu.com/p/5f8782bf15b1
```

**模型搭建**

1）上一步处理完的数据——获得建模数据

2）确定适合数据集的算法——监督学习还是无监督学习

3）模型的选择——可以根据任务、数据样本量及特征的稀疏性来决定

4）模型的搭建——先尝试基本的模型作为baseline，再训练其他模型做对比，最终选择泛化能力或性能较好的模型

**切割训练集和测试集**——以便后续评估模型泛化能力，其中测试集的比例有30%、25%、20%、15%和10%，从 sklearn.model_selection 中调用train_test_split 函数，具体使用方法如下

https://www.cnblogs.com/Yanjy-OnlyOne/p/11288098.html

```python
from sklearn.model_selection import train_test_split # 采用sklearn中的train_test_split对数据集进行切割

# 一般先取出X和y后再切割，有些情况会使用到未切割的，这时候X和y就可以用
X = data
y = train['Survived']

# 对数据集进行切割
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)
# stratify=y表示按照y中的比例分配
# random_state表示随机数的种子，即该组随机数的编号，在重复试验的时候，保证得到一组一样的随机数，若填0则表示在其他参数一样的情况下，得到的随机数组每次都不一样

# 查看数据形状
X_train.shape, X_test.shape
```

**模型的创建**——分类模型可基于线性模型（逻辑回归|所在模块：`sklearn.linear_model`）或基于树（决策树、随机森林|所在模块：`sklearn.ensemble`）

*逻辑回归需与LinearRegression区分

*随机森林其实是决策树集成为了降低决策树过拟合的情况

```python
from sklearn.linear_model import LogisticRegression # 逻辑回归
from sklearn.ensemble import RandomForestClassifier # 随机森林

# 默认参数逻辑回归模型
lr = LogisticRegression()
lr.fit(X_train, y_train)
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
verbose=0, warm_start=False)

# 查看训练集和测试集score值
print("Training set score: {:.2f}".format(lr.score(X_train, y_train)))
print("Testing set score: {:.2f}".format(lr.score(X_test, y_test)))


# 默认参数的随机森林分类模型
rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)

RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
max_depth=None, max_features='auto', max_leaf_nodes=None,
min_impurity_decrease=0.0, min_impurity_split=None,
min_samples_leaf=1, min_samples_split=2,
min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
oob_score=False, random_state=None, verbose=0,
warm_start=False)

print("Training set score: {:.2f}".format(rfc.score(X_train, y_train)))
print("Testing set score: {:.2f}".format(rfc.score(X_test, y_test)))
```

**输出模型预测结果**——利用sklearn中的`predict `输出预测标签， `predict_proba `则可以输出标签概率

```python
pred = lr.predict(X_train) # 预测标签
pred[:10] # 看到0和1的数组

pred_proba = lr.predict_proba(X_train) # 预测标签概率，与predict不同的是，返回的预测值为获得所有标签值可能性的概率，多少标签值就有多少概率
pred_proba[:10] 
```

**模型评估**——了解其泛化能力（交叉验证+ROC曲线）

**交叉验证（cross-validation）**——一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。在交叉验证中，数据被多次划分，并且需要训练多个模型。最常用的交叉验证是 k 折交叉验证（k-fold cross-validation），其中 k 是由用户指定的数字，通常取 5 或 10。目的是获得更可靠的模型

https://zhuanlan.zhihu.com/p/31924220

```python
from sklearn.model_selection import cross_val_score #交叉验证
lr = LogisticRegression(C=100)
scores = cross_val_score(lr, X_train, y_train, cv=10)

# k折交叉验证分数
scores
array([0.82352941, 0.79411765, 0.80597015, 0.80597015, 0.8358209 ,
0.88059701, 0.72727273, 0.86363636, 0.75757576, 0.71212121])

# 平均交叉验证分数
print("Average cross-validation score: {:.2f}".format(scores.mean()))
```

混淆矩阵是ROC曲线绘制的基础，同时它也是衡量分类型模型准确度中最基本，最直观，计算最简单的方法。一句话解释就是 ：混淆矩阵就是分别统计分类模型归错类，归对类的观测值个数，然后把结果放在一个表里展示出来。这个表就是混淆矩阵。

精确率（precision）度量的是被预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)：

![[公式]](https://www.zhihu.com/equation?tex=P++%3D+\frac{TP}{TP%2BFP})

召回率（recall）度量的是样本中的正例有多少被预测正确，相对于原来的样本而言。那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)。

![[公式]](https://www.zhihu.com/equation?tex=R+%3D+\frac{TP}{TP%2BFN})

其实就是分母不同，一个分母是预测为正的样本数，另一个是原来样本中所有的正样本数。

![image-20200828200923840](C:\Users\lauryn\AppData\Roaming\Typora\typora-user-images\image-20200828200923840.png)

F值是精确率与召回率的调和平均值

F值 = 精确率 * 召回率 * 2 / (精确确率 + 召回率) （F 值即为正确率和召回率的调和平均值）

```python
from sklearn.metrics import confusion_matrix # 混淆矩阵
# 训练模型
lr = LogisticRegression(C=100)
lr.fit(X_train, y_train)
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
verbose=0, warm_start=False)

# 模型预测结果
pred = lr.predict(X_train)

# 混淆矩阵
confusion_matrix(y_train, pred)

from sklearn.metrics import classification_report
# 精确率、召回率以及f1-score
print(classification_report(y_train, pred))
```

**ROC 曲线**作为评估模型的首选统计方法，曲线上平衡假阴性率和假阳性率所得的点叫工作点（operating point），每个点对应一个临界值threshold（也称阈值）。

ROC曲线下面所包围的面积越大越好，即AUC（Area Under Curve）越大越好，AUC越接近于1

```python
from sklearn.metrics import roc_curve
fpr, tpr, thresholds = roc_curve(y_test, lr.decision_function(X_test))
plt.plot(fpr, tpr, label="ROC Curve") 
plt.xlabel("FPR") # 横坐标
plt.ylabel("TPR (recall)") #纵坐标
# 找到最接近于0的阈值
close_zero = np.argmin(np.abs(thresholds))
plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10, label="threshold zero",
fillstyle="none", c='k', mew=2)
plt.legend(loc=4) # loc=4表示图例位置右边靠下
```

